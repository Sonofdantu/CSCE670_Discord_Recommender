{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328e022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe68090",
   "metadata": {},
   "source": [
    "## Author Relations (mention relations as ground truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b44c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('discord_author_game.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2bff46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing messages: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150000/150000 [00:51<00:00, 2935.56it/s]\n"
     ]
    }
   ],
   "source": [
    "name_to_id = dict(zip(df[\"Author\"], df[\"AuthorID\"]))\n",
    "name_set = set(name_to_id.keys())\n",
    "\n",
    "relations = set()\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing messages\"):\n",
    "    author_id = row[\"AuthorID\"]\n",
    "    author_name = row[\"Author\"]\n",
    "    content = str(row[\"Content\"])\n",
    "    for name in name_set:\n",
    "        if f\"@{name}\" in content and name != author_name:\n",
    "            target_id = name_to_id[name]\n",
    "            relations.add((author_id, target_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "877776c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df = pd.DataFrame(relations, columns=[\"FromAuthorID\", \"ToAuthorID\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d870d460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FromAuthorID</th>\n",
       "      <th>ToAuthorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125328264230207488</td>\n",
       "      <td>215456151268098058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>225323159145021440</td>\n",
       "      <td>215456151268098058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252458118775046144</td>\n",
       "      <td>194657909492285441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108632993685336064</td>\n",
       "      <td>215456151268098058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138144510285709312</td>\n",
       "      <td>456226577798135808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>99292154232332288</td>\n",
       "      <td>215456151268098058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>137785305586597888</td>\n",
       "      <td>456226577798135808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>228013037318176769</td>\n",
       "      <td>215456151268098058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>267784015547727873</td>\n",
       "      <td>265866596105322496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>146579602263900160</td>\n",
       "      <td>215195384136466442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           FromAuthorID          ToAuthorID\n",
       "0    125328264230207488  215456151268098058\n",
       "1    225323159145021440  215456151268098058\n",
       "2    252458118775046144  194657909492285441\n",
       "3    108632993685336064  215456151268098058\n",
       "4    138144510285709312  456226577798135808\n",
       "..                  ...                 ...\n",
       "388   99292154232332288  215456151268098058\n",
       "389  137785305586597888  456226577798135808\n",
       "390  228013037318176769  215456151268098058\n",
       "391  267784015547727873  265866596105322496\n",
       "392  146579602263900160  215195384136466442\n",
       "\n",
       "[393 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b918ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from collections import defaultdict\n",
    "known = {\"AuthorID\", \"Author\", \"Game\"}\n",
    "candidates = [c for c in df.columns if c not in known]\n",
    "\n",
    "text_col = candidates[0]   # we‚Äôll silently use the first extra column\n",
    "\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "# 3) Build sentiment‚Äëfiltered author‚Üígames map\n",
    "# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n",
    "analyzer            = SentimentIntensityAnalyzer()\n",
    "SENTIMENT_THRESHOLD = 0.2\n",
    "\n",
    "author_to_games   = defaultdict(list)\n",
    "author_id_to_name = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    aid  = str(row[\"AuthorID\"])\n",
    "    name = str(row[\"Author\"])\n",
    "    author_id_to_name[aid] = name\n",
    "\n",
    "    if pd.isna(row[\"Game\"]):\n",
    "        continue\n",
    "\n",
    "    message = str(row[text_col])\n",
    "    score   = analyzer.polarity_scores(message)[\"compound\"]\n",
    "    if score < SENTIMENT_THRESHOLD:\n",
    "        continue\n",
    "\n",
    "    games = [g.strip().lower() for g in row[\"Game\"].split(\",\") if g.strip()]\n",
    "    author_to_games[aid].extend(games)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8327c820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of author pairs with non-empty game mentions: 244\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for _, row in rel_df.iterrows():\n",
    "    from_id = str(row[\"FromAuthorID\"])\n",
    "    to_id   = str(row[\"ToAuthorID\"])\n",
    "\n",
    "    from_games = author_to_games.get(from_id, [])\n",
    "    to_games   = author_to_games.get(to_id, [])\n",
    "\n",
    "    if from_games and to_games:\n",
    "        count += 1\n",
    "\n",
    "print(f\"Number of author pairs with non-empty game mentions: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db543a44",
   "metadata": {},
   "source": [
    "## Evaluation of related pairs (with cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bd61f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/393 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 393/393 [00:00<00:00, 3705.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Valid overlapping pairs: 172\n",
      "üîç Average cosine similarity (with overlap): 0.1106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Build game index\n",
    "all_games = sorted(set(game for games in author_to_games.values() for game in games))\n",
    "game_to_index = {game: i for i, game in enumerate(all_games)}\n",
    "\n",
    "# Build author vectors (only include authors with at least one game)\n",
    "author_vectors = {}\n",
    "author_gamesets = {}\n",
    "for author_id, games in author_to_games.items():\n",
    "    if games:\n",
    "        vec = np.zeros(len(all_games))\n",
    "        for game in games:\n",
    "            if game in game_to_index:\n",
    "                vec[game_to_index[game]] = 1\n",
    "        author_vectors[author_id] = vec\n",
    "        author_gamesets[author_id] = set(games)\n",
    "\n",
    "# Compute cosine similarity for valid author pairs with overlapping games\n",
    "similarities = []\n",
    "valid_pairs = []\n",
    "\n",
    "for _, row in tqdm(rel_df.iterrows(), total=len(rel_df)):\n",
    "    aid1 = str(row[\"FromAuthorID\"])\n",
    "    aid2 = str(row[\"ToAuthorID\"])\n",
    "    \n",
    "    if aid1 in author_vectors and aid2 in author_vectors:\n",
    "        games1 = author_gamesets[aid1]\n",
    "        games2 = author_gamesets[aid2]\n",
    "        if games1 & games2:  # check for overlap\n",
    "            v1 = author_vectors[aid1].reshape(1, -1)\n",
    "            v2 = author_vectors[aid2].reshape(1, -1)\n",
    "            sim = cosine_similarity(v1, v2)[0][0]\n",
    "            similarities.append(sim)\n",
    "            valid_pairs.append((aid1, aid2, sim))\n",
    "\n",
    "if similarities:\n",
    "    avg_sim = sum(similarities) / len(similarities)\n",
    "    print(f\"‚úÖ Valid overlapping pairs: {len(similarities)}\")\n",
    "    print(f\"üîç Average cosine similarity (with overlap): {avg_sim:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid overlapping author pairs found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b81af3",
   "metadata": {},
   "source": [
    "## Evaluation of random pairs (with cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eaca46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Similarities: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:00<00:00, 22229.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Average cosine similarity for 1000 random pairs: 0.3587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "authors_with_games = [author_id for author_id, games in author_to_games.items() if games]\n",
    "\n",
    "\n",
    "num_samples = 1000  \n",
    "\n",
    "\n",
    "similarities = []\n",
    "\n",
    "\n",
    "for _ in tqdm(range(num_samples), desc=\"Calculating Similarities\"):\n",
    "\n",
    "    author1, author2 = random.sample(authors_with_games, 2)\n",
    "    \n",
    "    games1 = author_gamesets[author1]\n",
    "    games2 = author_gamesets[author2]\n",
    "    \n",
    "    if games1 & games2: \n",
    "        v1 = author_vectors[author1].reshape(1, -1)\n",
    "        v2 = author_vectors[author2].reshape(1, -1)\n",
    "        \n",
    "        \n",
    "        sim = cosine_similarity(v1, v2)[0][0]\n",
    "        similarities.append(sim)\n",
    "\n",
    "if similarities:\n",
    "    avg_sim = sum(similarities) / len(similarities)\n",
    "    print(f\"‚úÖ Average cosine similarity for {num_samples} random pairs: {avg_sim:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid pairs found for cosine similarity calculation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2ac02",
   "metadata": {},
   "source": [
    "## Evaluation of random pairs (with Jaccard similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09f0ca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 393/393 [00:00<00:00, 23493.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Average Jaccard similarity between related authors: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    set1, set2 = set(list1), set(list2)\n",
    "    if not set1 and not set2:\n",
    "        return 0.0\n",
    "    return len(set1 & set2) / len(set1 | set2)\n",
    "\n",
    "similarities = []\n",
    "\n",
    "for _, row in tqdm(rel_df.iterrows(), total=len(rel_df)):\n",
    "    aid1 = str(row[\"FromAuthorID\"])\n",
    "    aid2 = str(row[\"ToAuthorID\"])\n",
    "\n",
    "    games1 = author_to_games.get(aid1, [])\n",
    "    games2 = author_to_games.get(aid2, [])\n",
    "\n",
    "    if games1 and games2:\n",
    "        sim = jaccard_similarity(games1, games2)\n",
    "        similarities.append(sim)\n",
    "\n",
    "if similarities:\n",
    "    avg_similarity = sum(similarities) / len(similarities)\n",
    "    print(f\"üîç Average Jaccard similarity between related authors: {avg_similarity:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid author pairs with non-empty game lists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe9b6273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FromAuthorID</th>\n",
       "      <th>ToAuthorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125328264230207488</td>\n",
       "      <td>215456151268098058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>225323159145021440</td>\n",
       "      <td>215456151268098058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252458118775046144</td>\n",
       "      <td>194657909492285441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108632993685336064</td>\n",
       "      <td>215456151268098058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138144510285709312</td>\n",
       "      <td>456226577798135808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>99292154232332288</td>\n",
       "      <td>215456151268098058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>137785305586597888</td>\n",
       "      <td>456226577798135808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>228013037318176769</td>\n",
       "      <td>215456151268098058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>267784015547727873</td>\n",
       "      <td>265866596105322496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>146579602263900160</td>\n",
       "      <td>215195384136466442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           FromAuthorID          ToAuthorID\n",
       "0    125328264230207488  215456151268098058\n",
       "1    225323159145021440  215456151268098058\n",
       "2    252458118775046144  194657909492285441\n",
       "3    108632993685336064  215456151268098058\n",
       "4    138144510285709312  456226577798135808\n",
       "..                  ...                 ...\n",
       "388   99292154232332288  215456151268098058\n",
       "389  137785305586597888  456226577798135808\n",
       "390  228013037318176769  215456151268098058\n",
       "391  267784015547727873  265866596105322496\n",
       "392  146579602263900160  215195384136466442\n",
       "\n",
       "[393 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f076f",
   "metadata": {},
   "source": [
    "## Evaluation of ranking by BM25 (with MRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a4326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing MRR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 393/393 [00:04<00:00, 94.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MRR: 0.0455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "valid_pairs = []\n",
    "for _, row in rel_df.iterrows():\n",
    "    a1, a2 = str(row[\"FromAuthorID\"]), str(row[\"ToAuthorID\"])\n",
    "    g1 = author_to_games.get(a1, [])\n",
    "    g2 = author_to_games.get(a2, [])\n",
    "    if g1 and g2 and set(g1) & set(g2):\n",
    "        valid_pairs.append((a1, a2))\n",
    "\n",
    "\n",
    "documents = [author_to_games[aid] for aid in author_to_games]\n",
    "author_ids = list(author_to_games.keys())\n",
    "bm25 = BM25Okapi(documents)\n",
    "\n",
    "\n",
    "def compute_mrr(pairs, author_to_games, bm25, author_ids, top_k=100):\n",
    "    reciprocal_ranks = []\n",
    "\n",
    "    for a1, a2 in tqdm(pairs, desc=\"Computing MRR\"):\n",
    "        if a1 not in author_to_games or a2 not in author_to_games:\n",
    "            continue\n",
    "\n",
    "        query_tokens = author_to_games[a1]\n",
    "        if not query_tokens:\n",
    "            continue\n",
    "\n",
    "        scores = bm25.get_scores(query_tokens)\n",
    "        sorted_indices = sorted(range(len(scores)), key=lambda i: -scores[i])\n",
    "        sorted_authors = [author_ids[i] for i in sorted_indices]\n",
    "\n",
    "        if a2 in sorted_authors[:top_k]:\n",
    "            rank = sorted_authors.index(a2) + 1\n",
    "            reciprocal_ranks.append(1 / rank)\n",
    "\n",
    "    if reciprocal_ranks:\n",
    "        mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
    "        print(f\"‚úÖ MRR: {mrr:.4f}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No valid reciprocal ranks found.\")\n",
    "\n",
    "\n",
    "compute_mrr(valid_pairs, author_to_games, bm25, author_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8571ce4a",
   "metadata": {},
   "source": [
    "## Evaluation of ranking by TF-IDF (with MRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b286040",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scipy.sparse' has no attribute 'linalg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\discordbot\\lib\\site-packages\\sklearn\\__init__.py:73\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     __check_build,\n\u001b[0;32m     71\u001b[0m     _distributor_init,\n\u001b[0;32m     72\u001b[0m )\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     76\u001b[0m _submodules \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m ]\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\discordbot\\lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\discordbot\\lib\\site-packages\\sklearn\\utils\\__init__.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\discordbot\\lib\\site-packages\\sklearn\\utils\\_chunking.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\discordbot\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\discordbot\\lib\\site-packages\\sklearn\\utils\\validation.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _deprecate_force_all_finite\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ComplexWarning, _preserve_dia_indices_dtype\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\discordbot\\lib\\site-packages\\sklearn\\utils\\_array_api.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspecial\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[0;32m     19\u001b[0m _NUMPY_NAMESPACE_NAMES \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray_api_compat.numpy\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21myield_namespaces\u001b[39m(include_numpy_namespaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\discordbot\\lib\\site-packages\\sklearn\\utils\\fixes.py:114\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# TODO: Remove when Scipy 1.12 is the minimum supported version\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sp_base_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m parse_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.12.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 114\u001b[0m     _sparse_linalg_cg \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241m.\u001b[39mcg\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sparse_linalg_cg\u001b[39m(A, b, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scipy.sparse' has no attribute 'linalg'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "valid_pairs = []\n",
    "for _, row in rel_df.iterrows():\n",
    "    a1, a2 = str(row[\"FromAuthorID\"]), str(row[\"ToAuthorID\"])\n",
    "    g1 = author_to_games.get(a1, [])\n",
    "    g2 = author_to_games.get(a2, [])\n",
    "    if g1 and g2 and set(g1) & set(g2):\n",
    "        valid_pairs.append((a1, a2))\n",
    "\n",
    "\n",
    "author_ids = list(author_to_games.keys())\n",
    "docs = [\" \".join(author_to_games[aid]) for aid in author_ids] \n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(docs)  # shape: (num_authors, num_tokens)\n",
    "\n",
    "\n",
    "reciprocal_ranks = []\n",
    "for a1, a2 in tqdm(valid_pairs, desc=\"Computing TF-IDF MRR\"):\n",
    "    try:\n",
    "        idx_a1 = author_ids.index(a1)\n",
    "        idx_a2 = author_ids.index(a2)\n",
    "    except ValueError:\n",
    "        continue \n",
    "\n",
    "    query_vec = tfidf_matrix[idx_a1]\n",
    "    similarities = cosine_similarity(query_vec, tfidf_matrix).flatten()  # shape: (num_authors,)\n",
    "    ranked_indices = np.argsort(similarities)[::-1]  \n",
    "\n",
    "    if idx_a2 in ranked_indices:\n",
    "        rank = list(ranked_indices).index(idx_a2) + 1 \n",
    "        reciprocal_ranks.append(1.0 / rank)\n",
    "\n",
    "\n",
    "if reciprocal_ranks:\n",
    "    mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
    "    print(f\"‚úÖ TF-IDF MRR: {mrr:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid reciprocal ranks found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459114fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating MRR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3617212/3617212 [17:31<00:00, 3440.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fast MRR: 0.0043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "df = pd.read_csv(\"discord_author_game.csv\")  \n",
    "df[\"AuthorID\"] = df[\"AuthorID\"].astype(str)\n",
    "df[\"Game\"] = df[\"Game\"].astype(str)\n",
    "\n",
    "\n",
    "df[\"GameList\"] = df[\"Game\"].str.lower().str.split(\",\")\n",
    "rows = []\n",
    "for _, row in df.iterrows():\n",
    "    aid = row[\"AuthorID\"]\n",
    "    for game in row[\"GameList\"]:\n",
    "        rows.append((aid, game.strip()))\n",
    "\n",
    "df_expanded = pd.DataFrame(rows, columns=[\"AuthorID\", \"Game\"])\n",
    "df_expanded.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "author_idx = {aid: i for i, aid in enumerate(df_expanded[\"AuthorID\"].unique())}\n",
    "game_idx = {g: i for i, g in enumerate(df_expanded[\"Game\"].unique())}\n",
    "\n",
    "row_ind = df_expanded[\"AuthorID\"].map(author_idx)\n",
    "col_ind = df_expanded[\"Game\"].map(game_idx)\n",
    "data = np.ones(len(df_expanded))\n",
    "\n",
    "sparse_matrix = csr_matrix((data, (row_ind, col_ind)),\n",
    "                           shape=(len(author_idx), len(game_idx)))\n",
    "\n",
    "\n",
    "sim_matrix = cosine_similarity(sparse_matrix)\n",
    "\n",
    "authors = list(author_idx.keys())\n",
    "\n",
    "\n",
    "valid_pairs = []\n",
    "aid_to_games = df_expanded.groupby(\"AuthorID\")[\"Game\"].apply(set).to_dict()\n",
    "for i in range(len(authors)):\n",
    "    for j in range(i+1, len(authors)):\n",
    "        a1, a2 = authors[i], authors[j]\n",
    "        if aid_to_games[a1] & aid_to_games[a2]:  \n",
    "            valid_pairs.append((a1, a2))\n",
    "            valid_pairs.append((a2, a1))  \n",
    "\n",
    "\n",
    "reciprocal_ranks = []\n",
    "aid_to_idx = {aid: i for i, aid in enumerate(authors)}\n",
    "\n",
    "for a1, a2 in tqdm(valid_pairs, desc=\"Evaluating MRR\"):\n",
    "    idx1 = aid_to_idx[a1]\n",
    "    idx2 = aid_to_idx[a2]\n",
    "    sims = sim_matrix[idx1]\n",
    "    ranking = np.argsort(sims)[::-1]\n",
    "    ranked_authors = [authors[i] for i in ranking if authors[i] != a1]\n",
    "\n",
    "    if a2 in ranked_authors:\n",
    "        rank = ranked_authors.index(a2) + 1\n",
    "        reciprocal_ranks.append(1 / rank)\n",
    "\n",
    "\n",
    "if reciprocal_ranks:\n",
    "    mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
    "    print(f\"‚úÖ Fast MRR: {mrr:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid reciprocal ranks found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89919353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorID</th>\n",
       "      <th>Author</th>\n",
       "      <th>Content</th>\n",
       "      <th>Game</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111248848113909760</td>\n",
       "      <td>saticron</td>\n",
       "      <td>\\r\\nüí©üí©üí©üöΩüí©üöΩüöΩüí©\\r\\nüí©üöΩüöΩüöΩüí©üöΩüöΩüí©\\r\\nüí©üí©üöΩüöΩüí©üöΩüöΩüí©\\r\\nüí©üöΩüöΩüöΩüí©üöΩ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142447095830413312</td>\n",
       "      <td>psych3dout</td>\n",
       "      <td>k</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129272120336318464</td>\n",
       "      <td>bluntamputation</td>\n",
       "      <td>Memes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123641250879504384</td>\n",
       "      <td>brightqwerty</td>\n",
       "      <td>O shiiiiiit</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123641250879504384</td>\n",
       "      <td>brightqwerty</td>\n",
       "      <td>The shit post channel is born</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>456226577798135808</td>\n",
       "      <td>Deleted User</td>\n",
       "      <td>Oh awesome :D</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>287175303149649922</td>\n",
       "      <td>meephi2133</td>\n",
       "      <td>im back</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>174738347602870273</td>\n",
       "      <td>shinonny</td>\n",
       "      <td>Wb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>131041525185380352</td>\n",
       "      <td>dreams0129</td>\n",
       "      <td>steam has a ck2 sale</td>\n",
       "      <td>Crusader Kings II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>180687907965763584</td>\n",
       "      <td>livinguniverse</td>\n",
       "      <td>http://vignette4.wikia.nocookie.net/deusex/ima...</td>\n",
       "      <td>Deus Ex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AuthorID           Author  \\\n",
       "0       111248848113909760         saticron   \n",
       "1       142447095830413312       psych3dout   \n",
       "2       129272120336318464  bluntamputation   \n",
       "3       123641250879504384     brightqwerty   \n",
       "4       123641250879504384     brightqwerty   \n",
       "...                    ...              ...   \n",
       "149995  456226577798135808     Deleted User   \n",
       "149996  287175303149649922       meephi2133   \n",
       "149997  174738347602870273         shinonny   \n",
       "149998  131041525185380352       dreams0129   \n",
       "149999  180687907965763584   livinguniverse   \n",
       "\n",
       "                                                  Content               Game  \n",
       "0       \\r\\nüí©üí©üí©üöΩüí©üöΩüöΩüí©\\r\\nüí©üöΩüöΩüöΩüí©üöΩüöΩüí©\\r\\nüí©üí©üöΩüöΩüí©üöΩüöΩüí©\\r\\nüí©üöΩüöΩüöΩüí©üöΩ...                NaN  \n",
       "1                                                       k                NaN  \n",
       "2                                                   Memes                NaN  \n",
       "3                                             O shiiiiiit                NaN  \n",
       "4                           The shit post channel is born                NaN  \n",
       "...                                                   ...                ...  \n",
       "149995                                      Oh awesome :D                NaN  \n",
       "149996                                            im back                NaN  \n",
       "149997                                                 Wb                NaN  \n",
       "149998                               steam has a ck2 sale  Crusader Kings II  \n",
       "149999  http://vignette4.wikia.nocookie.net/deusex/ima...            Deus Ex  \n",
       "\n",
       "[150000 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b59fcc",
   "metadata": {},
   "source": [
    "## Evaluation of ranking by MF (with MRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d664ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing MRR with SVD: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 393/393 [00:00<00:00, 2812.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SVD-based MRR: 0.0615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "author_ids = list(author_to_games.keys())\n",
    "game_set = set(g for games in author_to_games.values() for g in games)\n",
    "game_ids = list(game_set)\n",
    "\n",
    "author_idx = {a: i for i, a in enumerate(author_ids)}\n",
    "game_idx = {g: i for i, g in enumerate(game_ids)}\n",
    "\n",
    "rows, cols, data = [], [], []\n",
    "for a in author_ids:\n",
    "    for g in author_to_games[a]:\n",
    "        rows.append(author_idx[a])\n",
    "        cols.append(game_idx[g])\n",
    "        data.append(1)\n",
    "\n",
    "interaction_matrix = csr_matrix((data, (rows, cols)), shape=(len(author_ids), len(game_ids)))\n",
    "\n",
    "\n",
    "n_components = min(32, interaction_matrix.shape[1] - 1)\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "author_embeddings = svd.fit_transform(interaction_matrix)\n",
    "\n",
    "\n",
    "sim_matrix = cosine_similarity(author_embeddings)\n",
    "\n",
    "\n",
    "aid_to_idx = author_idx\n",
    "\n",
    "\n",
    "def compute_mrr_svd(pairs, sim_matrix, author_ids, aid_to_idx, top_k=100):\n",
    "    reciprocal_ranks = []\n",
    "\n",
    "    for a1, a2 in tqdm(pairs, desc=\"Computing MRR with SVD\"):\n",
    "        if a1 not in aid_to_idx or a2 not in aid_to_idx:\n",
    "            continue\n",
    "\n",
    "        idx1 = aid_to_idx[a1]\n",
    "        idx2 = aid_to_idx[a2]\n",
    "\n",
    "        sims = sim_matrix[idx1]\n",
    "        sorted_indices = np.argsort(sims)[::-1]\n",
    "        ranked_aids = [author_ids[i] for i in sorted_indices if author_ids[i] != a1]\n",
    "\n",
    "        if a2 in ranked_aids[:top_k]:\n",
    "            rank = ranked_aids.index(a2) + 1\n",
    "            reciprocal_ranks.append(1 / rank)\n",
    "\n",
    "    if reciprocal_ranks:\n",
    "        mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
    "        print(f\"‚úÖ SVD-based MRR: {mrr:.4f}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No valid reciprocal ranks found.\")\n",
    "\n",
    "compute_mrr_svd(valid_pairs, sim_matrix, author_ids, aid_to_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76db1853",
   "metadata": {},
   "source": [
    "## Evaluation of ranking with embedding (with MRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5bd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [00:02<00:00, 24.41it/s]\n",
      "Computing MRR with Embedding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 393/393 [00:00<00:00, 3020.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding-based MRR: 0.1528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "author_to_text = {aid: \" \".join(games) for aid, games in author_to_games.items()}\n",
    "author_ids = list(author_to_text.keys())\n",
    "author_texts = [author_to_text[aid] for aid in author_ids]\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "author_embeddings = model.encode(author_texts, show_progress_bar=True)\n",
    "\n",
    "\n",
    "aid_to_idx = {aid: idx for idx, aid in enumerate(author_ids)}\n",
    "\n",
    "\n",
    "sim_matrix = cosine_similarity(author_embeddings)\n",
    "\n",
    "\n",
    "def compute_mrr_with_embedding(pairs, sim_matrix, author_ids, aid_to_idx, top_k=100):\n",
    "    reciprocal_ranks = []\n",
    "\n",
    "    for a1, a2 in tqdm(pairs, desc=\"Computing MRR with Embedding\"):\n",
    "        if a1 not in aid_to_idx or a2 not in aid_to_idx:\n",
    "            continue\n",
    "\n",
    "        idx1 = aid_to_idx[a1]\n",
    "        idx2 = aid_to_idx[a2]\n",
    "\n",
    "        sims = sim_matrix[idx1]\n",
    "        sorted_indices = np.argsort(sims)[::-1]\n",
    "        ranked_aids = [author_ids[i] for i in sorted_indices if author_ids[i] != a1]\n",
    "\n",
    "        if a2 in ranked_aids[:top_k]:\n",
    "            rank = ranked_aids.index(a2) + 1\n",
    "            reciprocal_ranks.append(1 / rank)\n",
    "\n",
    "    if reciprocal_ranks:\n",
    "        mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
    "        print(f\"‚úÖ Embedding-based MRR: {mrr:.4f}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No valid reciprocal ranks found.\")\n",
    "\n",
    "\n",
    "compute_mrr_with_embedding(valid_pairs, sim_matrix, author_ids, aid_to_idx)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discordbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
